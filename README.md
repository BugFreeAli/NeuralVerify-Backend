<div align="center">

  <h1>ğŸ§  NeuralVerify: The Engine</h1>
  <h3>State-of-the-Art Deepfake Detection API</h3>
  
  <p>
    <strong>A high-performance Microservice powered by EfficientNetV2 to detect Generative AI artifacts.</strong>
  </p>

  <p>
    <a href="https://bugfreeali-ai-real-detection.hf.space/docs"><strong>ğŸ”¥ Live API Docs</strong></a> â€¢
    <a href="#-benchmarks"><strong>ğŸ“Š Benchmarks</strong></a> â€¢
    <a href="#-architecture"><strong>ğŸ—ï¸ Architecture</strong></a>
  </p>

  <!-- BADGES -->
  <img src="https://img.shields.io/badge/Python-3.10-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/TensorFlow-2.17-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" />
  <img src="https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi&logoColor=white" />
  <img src="https://img.shields.io/badge/Docker-Enabled-2496ED?style=for-the-badge&logo=docker&logoColor=white" />
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" />

</div>

---

## âš¡ System Overview

**NeuralVerify Backend** is the computational core of the detection system. It hosts a custom-trained Convolutional Neural Network (CNN) capable of distinguishing between authentic photography and synthetic media generated by modern diffusion and flow-matching models.

Unlike generic classifiers, this engine was trained using an **Aggressive Fine-Tuning** strategy to detect high-frequency noise artifacts invisible to the human eye.

### ğŸš€ Key Technical Innovations
*   **Microservices Architecture:** Fully containerized using Docker for consistent inference on any cloud provider.
*   **Data Leakage Prevention:** Implemented a strict **Format Sanitization Pipeline** that converts all inputs to standard JPG (Quality 90) before training, preventing the model from "cheating" based on file headers (PNG vs JPG).
*   **Flux.1 Injection:** One of the first open-source detectors to include manually scraped data from the new **Flux.1** architecture.
*   **Robustness:** Trained with **Gaussian Noise Injection** to prevent overfitting on clean digital images.

---

## ğŸ—ï¸ Model Architecture

The system utilizes a **Transfer Learning** approach based on **EfficientNetV2-B0**.

| Component | Specification | Reason for Choice |
| :--- | :--- | :--- |
| **Base Model** | EfficientNetV2-B0 | Superior parameter efficiency and Fused-MBConv layers for texture analysis. |
| **Input Resolution** | 224x224 RGB | Optimized for detecting pixel-level noise artifacts. |
| **Optimizer** | AdamW | Handles weight decay better than standard Adam, preventing validation loss spikes. |
| **Training Strategy** | 3-Phase | 1. Frozen Base â†’ 2. Standard Fine-Tune â†’ 3. **Aggressive Fine-Tune (Top 100 Layers)**. |

---

## ğŸ“Š Benchmarks & Dataset

The model was trained on a balanced dataset of **~26,000 images** curated from three sources: **GenImage** (SD/Midjourney), **HardFake** (GANs), and **Flux Custom** (Flow Matching).

| Generator / Architecture | Detection Status | Accuracy (Est.) |
| :--- | :--- | :--- |
| **Stable Diffusion 1.5/2.1** | âœ… Supported | **98.2%** |
| **Midjourney v5** | âœ… Supported | **94.5%** |
| **StyleGAN (Faces)** | âœ… Supported | **99.0%** |
| **Flux.1 (Dev/Schnell)** | âœ… Supported | **~88%** |
| **DALL-E 3 (Photorealistic)** | âš ï¸ Experimental | ~75% |
| **Google Gemini / Imagen 3** | âŒ Limitation | Requires Transformer-specific training |

---

## ğŸ”Œ API Reference

The backend exposes a RESTful API via **FastAPI**.

### `POST /predict`
Upload an image file to receive a classification.

**Request:** `multipart/form-data`
- `file`: (Binary) The image file (JPG/PNG).

**Response:**
```json
{
  "prediction": "AI",
  "confidence_percentage": 98.45,
  "probabilities": {
    "ai": 0.9845,
    "real": 0.0155
  },
  "status": "success"
}
